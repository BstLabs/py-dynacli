{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to DynaCLI","text":"<p>Documentation: DynaCLI Github Pages</p> <p>Source Code: py-dynacli</p> <p>DynaCLI (Dynamic CLI) is a cloud-friendly Python library for converting pure Python functions into Linux Shell commands on the fly.</p> <p>Unlike other existing solutions such as Click and Typer, there is no need for any function decorators. Further, unlike all existing solutions, including those built on top of standard argparse, DynaCLI does not build all command parsers upfront, but rather builds dynamically a single command parser based on the command line inputs. When combined with the Python Cloud Importer solution DynaCLI becomes truly open concerning a practically unlimited set of commands, all coming directly from cloud storage. This, in turn, eliminates any need for periodic updates on client workstations.</p> <p>At its score, DynaCLI is a Python package structure interpreter which makes any public function executable from the command line.</p> <p>DynaCLI was developed by BST LABS as an open-source generic infrastructure foundation for the cloud version of Python run-time within the scope of the Cloud AI Operating System (CAIOS) project.</p> <p>DynaCLI is based on Python 3.9+, standard Python docstrings, and Python type hints.</p> <p>DynaCLI vital differentiators are:</p> <ul> <li>Fast: DynaCLI builds argparse parser hierarchy only for one command thus eliminating the need for preparing parsers for all available commands.</li> <li>Open: adding new command or group of commands (called feature) is as easy as dropping implementation module(s) in the right place of the import tree.</li> <li>Frameworkless: no need to import anything in command modules. Just write plain Python functions with built-in type arguments (*args and **kwargs are supported as well).</li> <li>Zero dependencies: only one module built on top of the standard Python library to install. No heavy dependencies dragged in.</li> <li>Robust: potential defect in any command will not take down the whole system.  </li> </ul>"},{"location":"types/","title":"Python types","text":"<p>If you need a refresher about how to use Python type hints, read here Python Type Checking (Guide).</p> <p>You can also check the mypy cheat sheet. In short (very short), you can declare a function with parameters like:</p> <pre><code>from enum import Enum\nclass Color(Enum):\nWHITE = 1\nRED = 2\ndef type_example(name: str, formal: bool, exit: int, amount: float, color: Color, *args: str, **kwargs: int):\npass\n</code></pre> <p>And your editor (and DynaCLI) will know that:</p> <ul> <li><code>name</code> is type of <code>str</code> and is a required parameter.</li> <li><code>formal</code> is type of <code>bool</code> and is a required parameter.</li> <li><code>exit</code> is type of <code>int</code> and is a required parameter.</li> <li><code>amount</code> is type of <code>float</code> and is a required parameter.</li> <li><code>color</code> is type of <code>Color</code> and is a required parameter.</li> <li><code>*args</code> variable length arguments with type of <code>str</code>.</li> <li><code>**kwargs</code> keyword arguments with type of <code>int</code>.</li> </ul> <p>These type hints are what give you autocomplete in your editor and several other features.</p> <p>DynaCLI is based on these type hints.</p>"},{"location":"advanced/docstrings/","title":"Supported Docstring format","text":"<p>You can read about available docstring formats in this article: Docstring Formats</p> <p>We opt for Google-style which is described here: PyGuide Functions and Methods</p> <p>You can use the following docstring as a reference:</p> test.py<pre><code>def test(name: str, age: int, is_student: bool, *args: str, **kwargs: int) -&gt; None:\n\"\"\"\n    The test function...\n    Args:\n        name (str): name of the applicant\n        age (int): age of the applicant\n        is_student (bool): if the applicant is a student or not\n        *args (str): some variable length arguments\n        **kwargs (int): keyword arguments\n    Return: None\n    \"\"\"\n</code></pre>"},{"location":"advanced/how_dynacli_works/","title":"How DynaCLI Works","text":"<p>DynaCLI library is a simple preprocessor for the argparse standard Python library. It scans the sys.argv array to process command line arguments one by one, uses the importlib.import_module function to bring in feature packages/modules and command modules, uses the inspect.signature to understand command function arguments and the re.match function to extract help string per argument. If it encounters a StopIteration or ModuleNotFound exception, it will use the pkgutil.iter_modules function to build help for available features and commands.</p> <p>The overall structure of the DynaCLI library is illustrated below:</p> <p></p>"},{"location":"advanced/search-path/","title":"DynaCLI search path and root packages","text":"<p>DynaCLI is supposed to be easy to use in easy cases and at the same time extremely flexible and cloud friendly. The last concept deserves some extra explanations.</p> <p>The DynaCLI was conceived to address the special needs of the Cloud AI Operating System (CAIOS) project, which employs a special custom Python Cloud Importer as the major underlying technology. Briefly, the main idea behind the CAIOS Python Cloud Importer is that developers do not need to <code>pip install</code> anything, but just to <code>import what_your_need</code> from the cloud storage.</p> <p>Here, we could envision at least three types of cloud storage where importable artifacts could be located:</p> <ul> <li>the main system cloud storage is shared by everybody (System Storage on the diagram below)</li> <li>cloud storage of a particular system installation shared by a group of developers (Group Storage on the diagram below)</li> <li>individual developer's storage (User Storage on the diagram below)</li> </ul> <p>Therefore, when a developer types <code>import something</code> this <code>something</code> could be imported from his/her User Storage, Group Storage shared with developers from her group, and System Storage shared with all developers. In fact, this is just the most typical system configuration. By itself, DynaCLI does not limit how many, or which types of storage should be in the system as long as they all are supported by the underlying Python Import System. Regardless of how many storages there are, each such storage should be reflected in the DynaCLI search_path list.</p> <p>On the other hand, in general cases, not all commands should be available to any user. Some commands are intended for developers but could be occasionally used by administrators. Some other commands should be available only for administrators of particular system installations (Group Administrator on the diagram below), while some other commands should be available for the system administrators. We, therefore need some form of command access control, be it Role-Base Access Control (RBAC) or even Attribute-Based Access Control (ABAC).</p> <p>DynaCLI addresses this need by assuming that each set of commands intended for a particular group of users (developers, administrators, etc.) is located under a particular Python Root Package and allows to configure them as a separate list in the DynaCLI entry point.</p> <p>Notice that the DynaCLI entry point does not have to be static. It could be dynamically generated at, say, system installation.</p> <p>Combining these two mechanisms, we come up with a many-to-many type of configuration, namely, that each type of storage might contain different root packages with commands intended for different types of users. This virtually unlimited flexibility in system configuration is what makes DynaCLI so different from any other Python CLI framework.</p> <p>Assuming AWS as a cloud platform (it will work equally well for any cloud, we just want to be specific), the diagram below illustrates a typical system configuration of 3 types of storage (System, Group, User) and two types of users (Developer, Administrator) accesses from two AWS cloud accounts:</p> <p></p> <p>Notice, that DynaCLI search path and root package configuration are not limited to cloud storage only (in this example AWS S3). Some artifacts could still be imported from a local disk for bootstrap or access time optimization purposes. There is virtually no limit to what could be achieved here.</p> <p>TODO: Shako to check if anything from below should be retained</p> <p>For DynaCLI search path has special meaning - it can use local packages or modules or those are stored in the cloud. There is no difference between whether it is getting imported from S3 or the local machine.</p> <p>Also, you can divide the functionality of your CLI - there can be situations where we need to provide some features for administrative users and some features to the developers. Basically, you can provide different search paths, and it will be reflected accordingly:</p> <p>Here we have 2 different CLIs <code>testcli</code> and <code>testcliadmin</code>. Accordingly, <code>testcliadmin</code> will see all features for the <code>dev</code> (<code>testcli</code>), because it is an admin:</p> <p>For Developers:</p> <pre><code>$ ./testcli -h\nusage: testcli [-h] [-v] {destroy,feature-A,service,update,fake,feature-B,the-last,upload} ...\nSample DynaCLI Tool\npositional arguments:\n  {destroy,feature-A,service,update,fake,feature-B,the-last,upload}\n    destroy             Destroy given name...\n    feature-A           Does something useful\n    service             This is an example of a module feature\n    update              Updates everything...\n    fake                [ERROR] Missing the module docstring\n    feature-B           Does something extremely useful\n    the-last            This is an example of a module feature\n    upload              This is an example of a module feature\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n</code></pre> <p>Administrators:</p> <pre><code>$ ./testcliadmin -h\nusage: testcliadmin [-h] [-v] {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D} ...\nSample DynaCLI Tool\npositional arguments:\n  {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D}\n    destroy             Destroy given name...\n    feature-A           Does something useful\n    service             This is an example of a module feature\n    update              Updates everything...\n    feature-C           For admin users\n    fake                [ERROR] Missing the module docstring\n    feature-B           Does something extremely useful\n    the-last            This is an example of a module feature\n    upload              This is an example of a module feature\n    feature-D           Do not forget about this feature for admins\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n</code></pre> <p>As you have noticed new 2 features were registered (<code>feature-C</code>, <code>feature-D</code>), and they can be either from the cloud or from the local.</p>"},{"location":"advanced/state-machine/","title":"DynalCLI State Machine","text":"<p>Internally, DynaCLI's main routine is implemented by applying the State Design Pattern (more specifically, function_for_state, but these are internal details) using a state machine for keeping track of the command line arguments processing progress. At a high level, this state machine, illustrated using the lightweight UML Statecharts notation, is presented below:</p> <p></p> <p>We treat every command line argument as a trigger trying to figure out what to do about it:</p> <ul> <li>the first entry of sys.argv is treated as a DynaCLI entry point, from which we extract high-level description and version info if any (_initial_state on the diagram)</li> <li>every next argument is treated as a Python module name, imported using the importlib.import_module function (_waiting_for_feature_or_command state on the diagram)</li> <li>if the import fails, or there are more entries in sys.arg, help for all available features (at the current level) is generated using the pkgutil.iter_modules function</li> <li>if import succeeds, the imported module is analyzed whether it has an <code>__all__</code> specifier or not (we follow Python convention concerning <code>__all__</code> specification)</li> <li>if it does have <code>__all__</code>, then based on whether it's a Python package or module, the processing transits to either <code>_waiting_for_package_feature_all</code> or <code>_waiting_for_module_feature_all</code> state (see below for more detailed description)</li> <li>otherwise, if the imported module is a package, we extract the package help and version info, if any, using the <code>__init__.py</code> file docstring and <code>__version__</code> specification and push the argparse parsers hierarchy one level down</li> <li>if it's a regular module, we check if it has a function with the same name</li> <li>if it does have a function with the same name, we treat it as a command module, build a complete command parser by analyzing the function signature and docstring, and transit to the final processing</li> <li>if it does not have a function with the same module, we treat it as a feature module (each public function will be treated as a command) and transit to _waiting_for_feature_module_command_state</li> <li>in the _waiting_for_package_feature_all state, we check whether the next sys.argv entry is in the <code>__all__</code> list; if it is we perform a normal state selection process outlined above, if it is not, we print a help message for this feature package</li> <li>in the _waiting_for_module_feature_all state, we check whether the next sys.argv entry is in the <code>__all__</code> list; if it is we treat it as a command, if it is not, we print a help message for this feature module</li> <li>in the _waiting_for_feature_module_command, we check whether the next sys.argv entry points to a public function within this module; if it does we treat it as a command, if it does not, we print a help message for this feature module</li> <li>at the final stage, we invoke the argparse standard parsing mechanism, check whether a pointer to the command function was obtained, and either execute this command if it was or print a usage message (argparse will print an error message if something was wrong)</li> </ul>"},{"location":"advanced/state-machine/#why-argparse-at-all","title":"Why argparse at all?","text":"<p>One could argue that DynaCLI uses the argparse for printing help and usage messages while actual processing is done by the DynaCLI internal machinery. If so, the question would be \"why use the argparse at all\".</p> <p>First, this observation is correct. Second, we wanted to retain the argparse message formatting, which is considered a de-facto standard. Third, considering limited resources and specific needs of the main CAIOS project, we did not want to invest in excavating help and usage message formatting from the argparse internals. While it might add some minor performance overhead we considered it negligible and worth our development effort savings.</p> <p>TODO: Shako to check whether anything from below still needs to be retained Each state corresponds to a different level.</p> <p>Effectively, we have 3 main states: feature as a package handler, feature as a module handler, and command handler.</p> <p>But there is a different state called <code>__all__</code> handler for going through a different path if there is a <code>__all__</code> indicated at feature as a package level and feature as a module level.</p> <p>There is no need to indicate <code>__all__</code> at the top-level command because it makes no sense.</p> <p>Basically, we treat each CLI sequence of the commands as different states:</p> <pre><code>$ ./testcli &lt;feature&gt; &lt;command&gt; -h\n</code></pre> <p>States in this CLI run are described below:</p> <p>At each iteration we find ourselves in a specific state, yes we use State Design Pattern:</p> <p>First iteration -&gt; <code>testcli</code> - the script itself is an initial state.</p> <p>Second iteration -&gt; <code>&lt;feature&gt;</code>- feature as package or feature as module state.</p> <p>Third iteration -&gt; <code>&lt;command&gt;</code> - command state.</p> <p>Fourth iteration -&gt; Iterator is exhausted and raised StopIteration which means we are going to build command help.</p> <p>Let's describe some more variations:</p> <p>Variations:</p> <p><code>./testcli -h</code> : initial state - StopIteration - build all features help</p> <p><code>./testcli &lt;feature as package&gt; -h</code> : initial state - add feature as parser - StopIteration - build feature help</p> <p><code>./testcli &lt;feature as module&gt; -h</code> : initial state - add feature as parser - StopIteration - build feature as module help</p> <p><code>./tescli &lt;feature&gt; &lt;command&gt; -h</code> : initial state - add feature parser - add command parser - StopIteration - build command help</p> <p><code>./tescli &lt;feature&gt; &lt;command&gt; arg1 arg2 \u2026</code> : initial state - add feature parser - add command parser - register arguments - execute the function</p> <p>And based on the fact that if <code>__all__</code> was found we got a different path to follow but the main idea is to have states for each path.</p> <p></p> <p>!!! NOTE</p> <pre><code>To explore UML please click and open the photo in large size\n</code></pre>"},{"location":"advanced/types/","title":"Supported Python Types","text":"<p>Currently, we support the following Python types as argument types in functions:</p> <p>Supported: <code>int</code>, <code>float</code>, <code>str</code>, <code>bool</code>, <code>Enum</code></p> <p>Unsupported: <code>Optional[]</code>, <code>Union[]</code>, <code>list</code>, <code>tuple</code>, <code>dict</code> etc.</p> <p>Even without unsupported type hints(and actual types) of arguments, you can easily replace them with <code>*args</code> and <code>**kwargs</code>, which are supported.</p>"},{"location":"advanced/why/","title":"DynaCLI vs. Alternatives","text":"<p>There are so many libraries out there for writing command-line utilities; why choose DynaCLI?</p> <p>Let's take a brief look at some common Python CLI libraries:</p> <ul> <li>Python argparse</li> <li>Google python-fire</li> <li>Tiangolo Typer</li> <li>Pallet's Click</li> </ul> <p>We'll review them one by one trying to understand the benefits and limitations of each:</p>"},{"location":"advanced/why/#python-argparse","title":"Python argparse","text":"<p>DynaCLI is built on top of argparse but the latter by itself is insufficient: it requires the manual construction of every parser. While this approach provides maximum flexibility, it's also tedious and error-prone. Also, typical usage of argparse assumes building all parsers and sub-parsers upfront. The irony is that each CLI invocation will execute only one command, so all other CPU cycles are wasted. When the number of commands is large, it starts to be a serious problem exacerbated by the fact that, in the case of Cloud AI Operating System (CAIOS), all command function modules come from cloud storage. Having said all this, argparse establishes an industry-wide standard of how CLI help and usage messages should look, and DynaCLI uses it internally as explained in more details here.</p>"},{"location":"advanced/why/#google-python-fire","title":"Google python-fire","text":"<p>This library shares with DynaCLI the main approach of converting ordinary Python functions into Bash commands. It even goes further, supporting class methods. DynaCLI does not support classes at the moment, but we may consider supporting them in the future (there is nothing spectacularly complex about classes). Google python-fire provides some additional attractive features such as function call chaining, interactivity, and shell completion. Like DynaCLI, Google python-fire is built on top of Python argparse and uses its internal machinery for configuring parsers and help and usage messages.</p> <p>Google python-fire also supports custom serialization, keyword arguments (with -- prefix), and direct access to object properties and local variables.</p> <p>Google python-fire does not rely on type annotations but rather converts command-line arguments to the most suitable types automatically on the fly.</p> <p>However, unlike DynaCLI, Google python-fire is not open concerning the potential number of commands and command groups (we call them features). Specifically, the main module should <code>import fire</code> (similar to <code>from dynacli import main</code>), but it also assumes either defining in place or importing ALL functions and classes one wants to convert into Bash commands. DynaCLI does not do this; instead, it relies on the search path and root package configurations, based on which any number of Python functions will be converted into commands automatically. While DynaCLI does not support classes at the moment (we simply did not see enough need for them), it does support unlimited nesting of command groups (feature packages) as well as a correct interpretation of <code>__all__</code> specification and package <code>__init__.py</code> imports.</p> <p>As the result, the Google python-fire library is relatively large: i.e., 10s of Python modules. In comparison, DynaCLI comprises one Python module with less than 700 lines, including blanks and docstrings. Library size and several features mean complexity and stability, and we were looking for something as small as possible... we seldom, if at all, will need to update.</p> <p>The main difference between DynaCLI and Google python-fire is that it was built with a distinct strategic goal in mind: to provide a minimal footprint for a completely extensible set of administrative commands coming from vendors and customers alike.</p> <p>Many extra features of Google python-fire that are missing in DynaCLI could be added as dynamic plugins if we decide to support them. Custom serialization would be a good example. We deliberately decided not to support them at this time, arguing that it would increase complexity without too much benefit: custom conversions of string arguments could be easily implemented at the command function level without the introduction of a parallel plugin structure. Following similar logic, we decided not to support named and optional arguments. We preferred treating command functions as belonging to the service layer, restricted to built-in type arguments with basic support for variable-length parameters via <code>*args</code> and <code>**kwargs</code>. Anything else could be implemented on top of that basic machinery without introducing added complexity and inflating the library's footprint.</p> <p>We will continue learning about Google python-fire and keeping track of its evolution. We will probably incorporate the most useful of its features into DynaCLI.</p>"},{"location":"advanced/why/#tiangolo-typer","title":"Tiangolo Typer","text":"<p>Conceptually, Tiangolo Typer usage is similar to that of Google python-fire - it converts plain Python functions into commands. Unlike Google python-fire and similar to DynaCLI, it does rely on argument types annotation. Unlike both of them, it is not implemented directly on top of Python argparse, but rather on top of Pallet's Click, which of course, inflates the overall library footprint, which we were trying to avoid in DynaCLI.</p> <p>Like DynaCLI, it generates automatically commands' help from function docstrings and type annotations.</p> <p>Feature-wise, Tiangolo Typer is very close to Google python-fire, but it leverages type annotations whenever possible. That in turn, allows effective integration with IDEs.</p> <p>It also uses colorama for controlling output colors. For that purpose, Tiangolo Typer recommends using its special <code>echo()</code> function. In DynaCLI, we decided not to pursue this direction at the moment, permitting every command function to print or log whatever it needs. As with many other command-line tools, we want to be able to develop service functions equally utilizable via CLI and REST API interfaces. For that reason, using Python Logging infrastructure is very often preferable. We also considered automatic printing (or logging) of function return values to be included in a future version. As with many other features, we want to avoid increasing the library footprint through features most daily operations could easily be performed without.</p> <p>Interestingly enough, Tiangolo Typer documentation mentions two other CLI Python frameworks: Hug and Plac. They both are based on Python function decorators and conceptually are similar to Pallet's Click.</p> <p>The main limitation of Tiangolo Typer is the same as with Google python-fire - ALL command functions have to be brought in (aka imported) upfront, which violates the basic DynaCLI premise to be a completely open and cloud-friendly library with a minimal installed footprint. By no means we were willing to trade these properties for more features and flexibility; more often than not these enhancements are not that critical or worth the extra complexity.</p>"},{"location":"advanced/why/#pallets-click","title":"Pallet's Click","text":"<p>This is probably the most widely used and powerful Python CLI library. It does not seem to be implemented on top of argparse, but rather on top of optparse - the argparse predecessor, which was deprecated since Python version 3.2 and has not been further developed.</p> <p>It has a relatively large footprint by itself (this needs to be taken into consideration for Tiangolo Typer).</p> <p>The main feature of Pallet's Click, which makes it so powerful and flexible, was an absolute no-go for us - it is based on Python function decorators. DynaCLI from the very outset was intended for converting into Bash commands regular Python functions that, at least in principle, could be reused in other contexts, such as REST API Services.</p>"},{"location":"advanced/why/#summary","title":"Summary","text":"<p>All the libraries mentioned above do not properly address the main DynaCLI requirements:</p> <ul> <li>complete openness - all command functions are brought in via dynamic imports from, presumably, cloud storage.</li> <li>no function decorators - command functions could be, at least in principle, reused in other contexts.</li> <li>minimal footprint - the core library has to be as small and as stable as possible, built on top of the standard Python library. All extra features, if any, should be introduced via dynamic imports.</li> </ul> <p>At the moment, the DynaCLI library satisfies all requirements of the sponsoring Cloud AI Operating System (CAIOS) project. Should additional needs or high-demand enhancements arise, such as command chaining or autocompletion, and these could be added without violating the main requirements outlined above, we will consider doing so in or accepting contributions to future versions of DynaCLI.</p>"},{"location":"manual/","title":"Reference Manual","text":"<p>This reference shows you how to use DynaCLI with most of its features, step by step.</p> <p>Each section gradually builds on the previous ones, but it's structured to separate topics, so that you can go directly to any specific one to solve your specific needs.</p> <p>It is also built to work as a future reference.</p> <p>So you can come back and see exactly what you need.</p>"},{"location":"manual/#install-dynacli","title":"Install DynaCLI","text":"<pre><code>$ pip3 install dynacli\n</code></pre> <p>As we have zero 3rd party dependencies, DynaCLI will just install a single module and that's it.</p>"},{"location":"manual/cli-entrypoint/","title":"Building CLI","text":"<p>We are going to build a simple CLI app in this tutorial. We called it <code>awesome</code>.</p> <p>First, let's define our project structure:</p> <pre><code>$ mkdir awesome\n$ touch awesome/awesome\n</code></pre> <p>Create the storages:</p> <pre><code>$ mkdir -p storage_X/cli/dev\n$ mkdir -p storage_Y/cli/dev\n</code></pre> <p>Now we will define our CLI entrypoint as:</p> <pre><code>#!/usr/bin/env python3\n\"\"\"\nDynaCLI bootstrap script # Change me\n\"\"\"\nimport os\nimport sys\nfrom typing import Final\nfrom dynacli import main\ncwd = os.path.dirname(os.path.realpath(__file__))\n__version__: Final[str] = \"1.0.0\"\nsearch_path = [f'{cwd}/storage_X/cli/dev', f'{cwd}/storage_Y/cli/dev']\nsys.path.extend(search_path)\n# root_packages = ['cli.dev', 'cli.admin'] # Change me if you have predefined root package name\n# main(search_path, root_packages) # Uncomment if you have root_packages defined\nmain(search_path)\n</code></pre> <p>If you wonder what is this <code>search_path</code>, please refer to the Search Path manipulation section of the Advanced Reference Manual.</p> <p>The next is to start adding packages as features.</p>"},{"location":"manual/module-as-feature/","title":"Module as feature","text":"<p>The module as a feature is a standalone module that is not located in the package(I.E it is not a package as a feature). It is a regular <code>.py</code> module file with functions in it - but it has no identical named function in it.</p> <p>Let's add module as a feature called <code>upload.py</code>:</p> <pre><code>$ touch storage_X/cli/dev/upload.py\n</code></pre> <p>And add the docstring in the <code>upload.py</code> file:</p> upload.py<pre><code>\"\"\"\nThis is an example of the module feature\n\"\"\"\n</code></pre> <p>If you run the CLI:</p> <pre><code>$ ./awesome -h\nusage: awesome [-h] {service,upload,environment} ...\npositional arguments:\n  {service,upload,environment}\n    service             The service feature to handle our services # (1)\n    upload              This is an example of module feature # (2)\n    environment         The environment feature to handle our environments # (3)\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <ol> <li>Package as a feature from storage_X</li> <li>Module as a feature from storage_X</li> <li>Package as a feature from storage_Y</li> </ol>"},{"location":"manual/module-as-feature/#feature-commands","title":"Feature Commands","text":"<p>With package as a feature, the commands are modules with identically named functions in them. In contrast, here we are going to add multiple functions in the <code>upload.py</code> - effectively multiple commands.</p> upload.py<pre><code>\"\"\"\nThis is an example of the module feature\n\"\"\"\ndef new(name: str) -&gt; None:\n\"\"\"\n    uploads a new file\n    Args:\n        name (str): Name of file\n    Return: None\n    \"\"\"\nprint(f\"This is a module as feature {name}\")\ndef delete(name: str, environment: str) -&gt; None:\n\"\"\"\n    Deletes a file from the given environment\n    Args:\n        name (str): Name of project\n        environment (str): Name of the env\n    Return: None\n    \"\"\"\nprint(f\"Delete a module as feature {name} {environment}\")\ndef _init():\n\"\"\"\n    This should not be shown\n    Return: None\n    \"\"\"\n...\ndef __revert():\n\"\"\"\n    This should not be shown\n    Return: None\n    \"\"\"\n...\n</code></pre> <p>In Python convention something starting with a single and double underscore is considered \"protected\" and \"private\" respectively.</p> <p>We like this idea and those commands(functions) are silently ignored and are not considered as commands:</p> <pre><code>$ ./awesome upload -h usage: awesome upload [-h] {new,delete} ...\npositional arguments:\n  {new,delete}\n    new         uploads a new file\n    delete      Deletes a file from given environment\noptional arguments:\n  -h, --help    show this help message and exit\n</code></pre> <p>Finally, let's run this new command:</p> <pre><code>$ ./awesome upload new -h\nusage: awesome upload new [-h] name\npositional arguments:\n  name        Name of file\noptional arguments:\n  -h, --help  show this help message and exit\n</code></pre> <pre><code>$ ./awesome upload new file\nThis is a module as a feature file\n</code></pre>"},{"location":"manual/module-as-feature/#versioning-module-as-a-feature","title":"Versioning module as a feature","text":"<p>As with packages as features, you can add <code>__version__</code> in the module as a feature to indicate your unique version:</p> upload.py<pre><code>\"\"\"\nThis is an example of the module feature\n\"\"\"\n__version__ = \"5.0\"\ndef new(name: str) -&gt; None:\n</code></pre> <p>Now you can get the version as well:</p> <pre><code>$ ./awesome upload new --version\nawesome upload new - v5.0\n</code></pre>"},{"location":"manual/module-as-feature/#limiting-the-feature-commands","title":"Limiting the feature commands","text":"<p>If for some reason you have a \"public\" function in the module, and you do not want to expose it as a command you can limit it by using <code>__all__</code>.</p> <p>Originally in Python <code>__all__</code> only limits the imports such as: from something import *.</p> <p>But here we use it just for eliminating the redundant operations when we register the feature commands:</p> upload.py<pre><code>\"\"\"\nThis is an example of the module feature\n\"\"\"\n__version__ = \"5.0\"\n__all__ = [\"new\"]\ndef new(name: str) -&gt; None:\n</code></pre> <p>Now if you look at the help of the feature:</p> <pre><code>$ ./awesome upload -h\nusage: awesome upload [-h] [-v] {new} ...\npositional arguments:\n  {new}\n    new          uploads a new file\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n</code></pre> <p>And if you try to bypass(because you are sure there is a delete function):</p> <pre><code>$ ./awesome upload delete -h\nusage: awesome upload [-h] [-v] {new} ...\nawesome upload: error: invalid choice: 'delete' (choose from 'new')\n</code></pre> <p>The next is to learn about top-level commands.</p>"},{"location":"manual/package-as-feature/","title":"Package as a feature","text":"<p>Now it is time to add our package as features:</p> <pre><code>$ mkdir storage_X/cli/dev/service\n$ touch storage_X/cli/dev/service/__init__.py\n\n$ mkdir storage_Y/cli/dev/environment\n$ touch storage_Y/cli/dev/environment/__init__.py\n</code></pre> <p>That's it you can now run your CLI:</p> <pre><code>$ ./awesome -h\n\nusage: awesome [-h] {service,environment} ...\npositional arguments:\n  {service, environment}\n    service             [ERROR] Missing the module docstring\n    environment         [ERROR] Missing the module docstring\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <p>Our packages have no docstrings in them, due to this fact we got an <code>ERROR</code> indicating that we are missing the docstrings.</p> <p>Let's quickly fix this. We are going to add docstrings to the <code>__init__.py</code> files.</p> <p>Open the <code>storage_X/cli/dev/service/__init__.py</code> and add the following:</p> <pre><code>\"\"\"The service feature to handle our services\"\"\"\n</code></pre> <p>Open the <code>storage_Y/cli/dev/environment/__init__.py</code> and add the following:</p> <pre><code>\"\"\"The environment feature to handle our environments\"\"\"\n</code></pre> <p>Now if you rerun the CLI you can see that there are no <code>ERROR</code>s:</p> <pre><code>$ ./awesome -h\n\nusage: awesome [-h] {service,environment} ...\npositional arguments:\n  {service, environment}\n    service             The service feature to handle our services\n    environment         The environment feature to handle our environments\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre>"},{"location":"manual/package-as-feature/#feature-commands","title":"Feature commands","text":"<p>What kind of operations do we want for our service feature?  Let's imagine that we can create, update, and shut down the services. That means we need <code>new.py</code>, <code>update.py</code>, and <code>shutdown.py</code> files in the service package:</p> <pre><code>$ touch storage_X/cli/dev/service/new.py\n$ touch storage_X/cli/dev/service/update.py\n$ touch storage_X/cli/dev/service/shutdown.py\n</code></pre> <p>We consider commands in the package as features if they have an identically named function in them. In other words, there should be <code>new()</code> function in <code>new.py</code>, <code>update()</code> in <code>update.py</code> etc.</p> <p>So, let's define our functions(feature commands):</p> new.py<pre><code>def new(name: str, path: str):\n\"\"\"\n    init the new project in the given path\n    Args:\n        name (str): name of the project\n        path (str): path where to create service\n    Return: None\n    \"\"\"\nprint(f\"Initializing the {name} in {path}\")\n</code></pre> update.py<pre><code>def update(name: str, version: float, upgrade: bool, *args: str, **kwargs: int) -&gt; None:\n\"\"\"\n    updates the service...\n    Args:\n        name (str): name of the service\n        version (float): new version\n        upgrade (bool): if to upgrade everything\n        *args (str): variable length arguments\n        **kwargs (int): keyword arguments\n    Return: None\n    \"\"\"\nprint(f\"Updating...{name} to {version} with {upgrade=} using {args} and {kwargs}\")\n</code></pre> shutdown.py<pre><code>def shutdown(environment: str, service: str) -&gt; None:\n\"\"\"\n    shutdown the service\n    Args:\n        environment (str): environment name (e.g. Cloud9 IDE stack)\n        service (str): name of the service\n    Return: None\n    \"\"\"\nprint(f\"This is a shutdown of {service} from {environment}!\")\n</code></pre> <p>Now let's get information about service feature:</p> <pre><code>$ ./awesome service -h\nusage: awesome service [-h] {new,shutdown,update} ...\npositional arguments:\n  {new,shutdown,update}\n    new                 init the new project in the given path\n    shutdown            shutdown the service\n    update              updates the service...\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <p>How about each command?</p> <pre><code>$ ./awesome service update -h\nusage: awesome service update [-h] name version upgrade [args ...] [kwargs &lt;name&gt;=&lt;value&gt; ...]\npositional arguments:\n  name                  name of the service\n  version               new version\n  upgrade               if to upgrade everything\n  args                  variable length arguments\n  kwargs &lt;name&gt;=&lt;value&gt;\n                        keyword arguments\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <p>Now let's call the update command:</p> <pre><code>$ ./awesome service update myservice 2.0 True lib1 lib2 version1=1.2 version2=1.3\n\nUpdating... myservice to 2.0 with upgrade=True using ('lib1', 'lib2') and {'version1': 1.2, 'version2': 1.3}\n</code></pre> <p>As you have already noticed we have converted the CLI commands to the function arguments with proper type conversion.</p>"},{"location":"manual/package-as-feature/#versioning-your-features-and-commands","title":"Versioning your features and commands","text":"<p>Now imagine the case, when for some reason you have a bunch of features with different versions, and also your commands have different versioning. You can easily handle it, by adding <code>__version__</code> in the feature and commands.</p> <p>Open the <code>storage_X/cli/dev/service/__init__.py</code> and add:</p> <pre><code>\"\"\"The service feature to handle our services\"\"\"\n__version__ = \"1.0\"\n</code></pre> <p>Now you can get the version of the feature:</p> <pre><code>$ ./awesome service --version\n\nawesome service - v1.0\n</code></pre> <p>Same for <code>update</code> command:</p> update.py<pre><code>__version__ = \"2.0\"\ndef update(name: str, version: float, upgrade: bool, *args: str, **kwargs: float) -&gt; None:\n...\n</code></pre> <pre><code>$ ./awesome service update --version\n\nawesome service update - v2.0\n</code></pre>"},{"location":"manual/package-as-feature/#limiting-the-feature-commands","title":"Limiting the feature commands","text":"<p>You may have a situation when you have other helper modules inside the feature package, and you do not want to expose them as a feature command. In that case, you can leverage the <code>__all__</code> mechanism. Originally in Python <code>__all__</code> only limits the imports such as: <code>from something import *</code>. But here we use it just for eliminating the redundant operations when we register the feature commands.</p> <p>So let's eliminate the <code>shutdown</code> command from our <code>service</code> feature without removing it.</p> <p>Update the <code>__init__.py</code> file of the service feature:</p> <pre><code>\"\"\"The service feature to handle our services\"\"\"\nfrom . import *\n__version__ = \"1.0\"\n__all__ = [\"new\", \"update\"]\n</code></pre> <p>And now try to get the help, as you have already noticed <code>shutdown</code> command is not available:</p> <pre><code>$ ./awesome service -h\n\nusage: awesome service [-h] [-v] {new,update} ...\npositional arguments:\n  {new,update}\n    new          init the new project in given path\n    update       Updates the service...\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n</code></pre> <p>If you try to bypass this guard(because you know that there is a shutdown.py file indeed):</p> <pre><code>$ ./awesome service shutdown -h\n\nusage: awesome service [-h] [-v] {new,update} ...\nawesome service: error: invalid choice: 'shutdown' (choose from 'new', 'update')\n</code></pre> <p>The next is to explore modules as features.</p>"},{"location":"manual/top-level-command/","title":"Top Level Command","text":"<p>The top-level command is a module with an identically named function in it. It is similar to a package as a feature, except it is a module, not a package. I.E it is a module as a feature with an identically named function in it.</p> <p>Let's create sample one:</p> <pre><code>$ touch storage_X/cli/dev/destroy.py\n</code></pre> <p>Define the command as:</p> destroy.py<pre><code>def destroy(name: str) -&gt; None:\n\"\"\"\n    Destroy given name...(top-level command)\n    Args:\n        name (str): Name of project\n    Return: None\n    \"\"\"\nprint(f\"This is a top level destroyer - {name}\")\n</code></pre> <p>Get the help message:</p> <pre><code>$ ./awesome -h\nusage: awesome [-h] {destroy,service,upload,environment} ...\npositional arguments:\n  {destroy,service,upload,environment}\n    destroy             Destroy given name...(top-level command) # (1)\n    service             The service feature to handle our services # (2)\n    upload              This is an example of module feature # (3)\n    environment         The environment feature to handle our environments # (4)\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <ol> <li>Top-level command from storage_X</li> <li>Package as a feature from storage_X</li> <li>Module as a feature from storage_X</li> <li>Package as a feature from storage_Y</li> </ol> <p>Get the top-level command help:</p> <pre><code>$ ./awesome destroy -h\nusage: awesome destroy [-h] name\npositional arguments:\n  name        Name of project\noptional arguments:\n  -h, --help  show this help message and exit\n</code></pre> <p>Run the top-level command:</p> <pre><code>$ ./awesome destroy please\nThis is a top-level destroyer - please\n</code></pre>"},{"location":"manual/top-level-command/#versioning","title":"Versioning","text":"<p>You can add a unique version to your top level command by adding <code>__version__</code>:</p> destroy.py<pre><code>__version__ = \"1.1a1\"\ndef destroy(name: str) -&gt; None:\n</code></pre> <p>Get the version information:</p> <pre><code>./awesome destroy -h\nusage: awesome destroy [-h] [-v] name\npositional arguments:\n  name           Name of project\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n</code></pre> <pre><code>$ ./awesome destroy --version\nawesome destroy - v1.1a1\n</code></pre>"},{"location":"todo-app/","title":"TODO app","text":"<p>We use a To-Do app idea from Build a Command-Line To-Do App With Python and Typer. Of course, we are going to change and omit unneeded sections. The goal is to show how DynaCLI can ease the process of building CLI apps.</p> <p>Create the TODO directory and create the todo file: <pre><code>$ mkdir TODO\n$ dynacli init todo path=TODO/\n</code></pre></p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u2514\u2500\u2500 todo\n\n1 directory, 1 file\n</code></pre> <p>CLI entrypoint is quite simple without any pre-configuration:</p> todo<pre><code>#!/usr/bin/env python3\n\"\"\"\nTODO CLI APP\n\"\"\"\nimport os\nimport sys\nfrom typing import Final\nfrom dynacli import main\ncwd = os.path.dirname(os.path.realpath(__file__))\n__version__: Final[str] = \"1.0.0\"\nsearch_path = [cwd]\nsys.path.extend(search_path)\nmain(search_path)\n</code></pre> <p>And now we have nice help with the description and the version. Essentially, we get the CLI help from the docstring, version from <code>__version__</code> and there is no need for any callback.</p> <pre><code>$ ./todo -h\nusage: todo [-h] [-v] {} ...\nTODO CLI APP\npositional arguments:\n  {}\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n</code></pre> <pre><code>$ ./todo --version\ntodo - v1.0\n</code></pre> <p>The next step is to initiate the TODO project.</p>"},{"location":"todo-app/init/","title":"todo init command","text":"<p>The simplest way of storing our todos is constructing a .json file with given name. At this point, it is different from original post,  and we consider it is simpler to store tasks as: <code>(Status, Task name)</code> style in the <code>.json</code> file. We consider the database as a project name where the tasks should reside. If you want to create task management for your daily routine - that means, we need to init the daily database(or daily project).</p> <p>This is called initialization, so we have created the <code>init.py</code> file:</p> <pre><code>$ cd TODO\n$ touch init.py\n$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u2514\u2500\u2500 todo\n1 directory, 2 files\n</code></pre> init.py<pre><code>import json\ndef init(project_name: str) -&gt; None:\n\"\"\"\n    Initialize the .json file with a given name\n    Args:\n        project_name (str): the name of the todo project\n    Return: None\n    \"\"\"\ndata = {project_name: []}\nwith open(f\"{project_name}.json\", \"w\") as f:\njson.dump(data, f)\nprint(\"Created: \", project_name+\".json\")\n</code></pre> <p>That is it now we have a nice help message, and we can initialize our \"database\" - JSON file:</p> <pre><code>$ ./todo init -h\nusage: todo init [-h] project_name\npositional arguments:\n  project_name  the name of the todo project\noptional arguments:\n  -h, --help    show this help message and exit\n</code></pre> <p>Run the init command:</p> <pre><code>$ ./todo init daily\nCreated:  daily.json\n</code></pre> <p>The final tree:</p> <pre><code>$ tree -I __pycache__\n.\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 daily.json\n\u2514\u2500\u2500 todo\n0 directories, 3 files\n</code></pre> <p>The next command is to implement the <code>todo remove</code> command - I.E deleting the \".json\" file.</p>"},{"location":"todo-app/remove-project/","title":"todo remove command","text":"<p>Again, removing project(database) means removing our .json file. The most naive way is to create the <code>remove.py</code> file and pass the project name as an argument:</p> <pre><code>$ touch remove.py\n$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u2514\u2500\u2500 todo\n1 directory, 3 files\n</code></pre> remove.py<pre><code>import os\ndef remove(project_name: str) -&gt; None:\n\"\"\"\n    Remove the .json file with a given project name\n    Args:\n        project_name (str): The name of the project\n    Return: None\n    \"\"\"\nos.remove(f\"{project_name}.json\")\nprint(\"Removed: \", project_name)\n</code></pre> <p>Let's get help and remove our <code>daily</code> project:</p> <pre><code>$ ./todo -h\nusage: todo [-h] [-v] {init,remove} ...\nTODO CLI APP\npositional arguments:\n  {init,remove}\n    init         Initialize the .json file with given name\n    remove       Remove the .json file with given project name\noptional arguments:\n  -h, --help     show this help message and exit\n  -v, --version  show program's version number and exit\n</code></pre> <pre><code>$ ./todo remove daily\nRemoved:  daily\n</code></pre> <p>The final tree:</p> <pre><code>$ tree -I __pycache__\n.\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 remove.py\n\u2514\u2500\u2500 todo\n0 directories, 3 files\n</code></pre> <p>The next command is <code>todo rename</code> which should rename our project.</p>"},{"location":"todo-app/rename-project/","title":"todo rename command","text":"<p>For renaming our project(database) we need the old name and a new name as function arguments to our <code>rename.py</code>.</p> <pre><code>$ touch rename.py\n$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u2514\u2500\u2500 todo\n1 directory, 4 files\n</code></pre> rename.py<pre><code>import os\ndef rename(old_name: str, new_name: str) -&gt; None:\n\"\"\"\n    Rename the project name\n    Args:\n        old_name (str): old name of the project\n        new_name (str): new name of the project\n    Return: None\n    \"\"\"\nos.rename(f\"{old_name}.json\", f\"{new_name}.json\")\nprint(f\"Renamed: {old_name} {new_name}\")\n</code></pre> <p>Get the help:</p> <pre><code>$ ./todo rename -h\nusage: todo rename [-h] old_name new_name\npositional arguments:\n  old_name    old name of the project\n  new_name    new name of the project\noptional arguments:\n  -h, --help  show this help message and exit\n</code></pre> <p>Initializing:</p> <pre><code>$ ./todo init daily\nCreated:  daily.json\n</code></pre> <pre><code>$ tree -I __pycache__\n.\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 daily.json\n\u251c\u2500\u2500 remove.py\n\u251c\u2500\u2500 rename.py\n\u2514\u2500\u2500 todo\n0 directories, 5 files\n</code></pre> <p>Renaming:</p> <pre><code>$ ./todo rename daily DAILY\nRenamed: daily DAILY\n</code></pre> <pre><code>$ tree -I __pycache__\n.\n\u251c\u2500\u2500 init.py\n\u251c\u2500\u2500 DAILY.json\n\u251c\u2500\u2500 remove.py\n\u251c\u2500\u2500 rename.py\n\u2514\u2500\u2500 todo\n0 directories, 5 files\n</code></pre> <p>So far our TODO CLI has 3 features:</p> <pre><code>$ ./todo -h\nusage: todo [-h] [-v] {init,remove,rename} ...\nTODO CLI APP\npositional arguments:\n  {init,remove,rename}\n    init                Initialize the .json file with given name\n    remove              Remove the .json file with given project name\n    rename              Rename the project name\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n</code></pre> <p>The next is to set up our task management commands.</p>"},{"location":"todo-app/task/task-add/","title":"todo task add command","text":"<p>As task management logically is a group of commands it is better to add them to the <code>task</code> package:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n3 directories, 8 files\n</code></pre> __init__.py<pre><code>\"\"\"\nTask management commands\n\"\"\"\n</code></pre> <p>Get the overall help:</p> <pre><code>$ ./todo -h\nusage: todo [-h] [-v] {init,remove,rename,task} ...\nTODO CLI APP\npositional arguments:\n  {init,remove,rename,task}\n    init                Initialize the .json file with given name\n    remove              Remove the .json file with given project name\n    rename              Rename the project name\n    task                Task management commands\noptional arguments:\n  -h, --help            show this help message and exit\n  -v, --version         show program's version number and exit\n</code></pre> <p>As you may notice the <code>_todos</code> package was ignored as it is considered as \"non-public\" - pure Python convention.</p> <p>So, the DynaCLI does not interfere with any already existing codebase.</p> <p>To implement the task adding, we need to create the <code>add.py</code> file:</p> <pre><code>tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n3 directories, 9 files\n</code></pre> <p>Here we use as a reference Implement the add CLI Command.</p> <p>And of course, define the add function in the <code>add.py</code>:</p> add.py<pre><code>from _todos import todo\ndef add(project_name: str, task: str, *tasks: str) -&gt; None:\n\"\"\"\n    Add a task to the project\n    Args:\n        project_name (str): the project name\n        task (str): task name\n        *tasks (str): variable length argument\n    Return: None\n    \"\"\"\ntodo_ = todo.get_todoer(project_name)\nfor t in [task, *tasks]:\ntodo_.add(t)\nprint(\"Success\")\n</code></pre> <p>Next is to add the implementations of <code>add</code> and <code>add_multiple</code> methods in Todoer class:</p> _todos/todo.py<pre><code>import os\nfrom .database import DatabaseHandler\nfrom typing import NamedTuple, Any\nfrom . import DB_READ_ERROR\nDIR = os.path.dirname(__file__)\nclass CurrentTodo(NamedTuple):\ntodo: dict[str, list[tuple[str]]]\nerror: int\nclass Todoer:\ndef __init__(self, project_name: str) -&gt; None:\nself.project_name = project_name\nself._db_handler = DatabaseHandler(DIR + f\"/../{project_name}.json\")\ndef add(self, task: str) -&gt; CurrentTodo:\nread = self._db_handler.read_todos()\nif read.error == DB_READ_ERROR:\nreturn CurrentTodo(read.todo_list, read.error)\nread.todo_list[self.project_name].append([\"Todo\", task])\nwrite = self._db_handler.write_todos(read.todo_list)\nreturn CurrentTodo(write.todo_list, write.error)\ndef add_multiple(self, tasks: tuple[str]) -&gt; None:\nread = self._db_handler.read_todos()\nfor task_ in tasks:\nread.todo_list[self.project_name].append([\"Todo\", task_])\nself._db_handler.write_todos(read.todo_list)\ndef get_todoer(project_name: str) -&gt; Todoer:\nreturn Todoer(project_name)\n</code></pre> <p>Now let's test our CLI:</p> <pre><code>$ ./todo init daily\nCreated:  daily.json\n</code></pre> <p>Adding 2 daily tasks:</p> <pre><code>$ ./todo task add daily \"morning walk\"\nSuccess\n$ ./todo task add daily \"night walk\"\nSuccess\n</code></pre> <p>Now the daily.json file looks like: <code>{\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"]]}</code>.</p> <p>How about adding multiple tasks in one shot?</p> <p>Adding multiple daily tasks:</p> <pre><code>$ ./todo task add daily gym \"eat vegetables\" \"eat fruits\"\nSuccess\n</code></pre> <p>If you check the <code>daily.json</code>: <code>{\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"], [\"Todo\", \"eat fruits\"]]}</code></p> <p>If you have already noticed every task is by default marked as <code>\"Todo\"</code>.</p> <p>The next topic is to add the <code>todo task list</code> command.</p>"},{"location":"todo-app/task/task-clear/","title":"todo task clear command","text":"<p>How about removing all tasks? I.E clearing the project?</p> <p>The idea is similar to the Implement the clear CLI Command</p> <p>First, we need to update the Todoer controller:</p> _todos/todo.py<pre><code>...\nclass Todoer:\n...\ndef remove_all(self) -&gt; CurrentTodo:\n\"\"\"Remove all to-dos from the database.\"\"\"\nwrite = self._db_handler.write_todos({f\"{self.project_name}\": []})\nreturn CurrentTodo({}, write.error)\n...\n</code></pre> <p>The next thing is to create the <code>clear.py</code> file in the <code>task</code> package:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 clear.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 complete.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 delete.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 list.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n\n3 directories, 13 files\n</code></pre> <p>The actual implementation is similar to the original blog post, here we are intentionally using a decorator as a prompt:</p> task/clear.py<pre><code>from functools import wraps\nfrom _todos import todo\ndef _prompt(func_: callable) -&gt; callable:\n@wraps(func_)\ndef wrapper(project_name: str):\nwhile True:\nchoice = input(\"Delete all to-dos? [y/N]:\")\nif 'y' == choice:\nreturn func_(project_name)\nelif 'N' == choice:\nprint('Operation cancelled')\nexit(1)\nprint('Invalid choice. Try again')\nreturn wrapper\n@_prompt\ndef clear(project_name: str) -&gt; None:\n\"\"\"\n    Deleting all tasks\n    Args:\n        project_name (str): the project name\n    Return: None\n    \"\"\"\ntodo_ = todo.get_todoer(project_name)\ntodo_.remove_all()\nprint(\"All to-dos were removed\")\n</code></pre> <p>Get the help of the <code>clear</code> command:</p> <pre><code>$ ./todo task clear -h\nusage: todo task clear [-h] project_name\npositional arguments:\n  project_name  the project name\noptional arguments:\n  -h, --help    show this help message and exit\n</code></pre> <p>As you see, the actual code and also the <code>DynaCLI</code> implementation did not interfere with the <code>_prompt</code> decorator.</p> <p>Let's test our clear command:</p> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 &gt; morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n</code></pre> <pre><code>$ ./todo task clear daily\nDelete all to-dos? [y/N]:N\nOperation canceled\n</code></pre> <pre><code>./todo task clear daily\nDelete all to-dos? [y/N]:sasd\nInvalid choice. Try again\nDelete all to-dos? [y/N]:y\nAll to-dos were removed\n</code></pre> <pre><code>$ /todo task list daily\nID. Is Done | Description\n</code></pre> <p>Dead simple. <code>DynaCLI</code> just converted <code>clear</code> function to the CLI <code>clear</code> command(yes it works with decorated functions).</p>"},{"location":"todo-app/task/task-delete/","title":"todo task delete command","text":"<p>We should be able to delete a given task from a given project. Let's implement this command as well. You need to create the <code>delete.py</code> file:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 delete.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 list.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n3 directories, 11 files\n</code></pre> <p>Next, we need to add delete functionality to our Todoer controller.</p> <p>The following code portion is from Implement the remove CLI Command</p> _todos/todo.py<pre><code>...\nclass Todoer:\n...\ndef delete(self, task_id: int) -&gt; CurrentTodo:\n\"\"\"Delete a to-do from the database using its id or index.\"\"\"\nread = self._db_handler.read_todos()\nif read.error:\nreturn CurrentTodo({}, read.error)\ntry:\nread.todo_list[self.project_name].pop(task_id - 1)\nexcept IndexError:\nreturn CurrentTodo({}, ID_ERROR)\nwrite = self._db_handler.write_todos(read.todo_list)\nreturn CurrentTodo(write.todo_list, write.error)\n...\n</code></pre> <p>Add the actual delete command:</p> delete.py<pre><code>from _todos import todo\ndef delete(project_name: str, task_id: int) -&gt; None:\n\"\"\"\n    Delete given task from the project\n    Args:\n        project_name (str): the project name\n        task_id (str): the task id to be removed\n    Return: None\n    \"\"\"\ntodo_ = todo.get_todoer(project_name)\ntodo_.delete(task_id)\nprint(\"Success\")\n</code></pre> <p>Let's test our delete command:</p> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 X morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n5 X eat fruits\n</code></pre> <p>Removing night walk from our daily routine(not in real life):</p> <pre><code>$ ./todo task delete daily 5\nSuccess\n</code></pre> <p>List tasks again:</p> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 X morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n</code></pre> <p>Again, as you have already noticed everything is dead simple and CLI depends on what you wrote in pure Python, translating arguments to CLI arguments. As a result, you don't have to write extra CLI command code - every function is already a command.</p>"},{"location":"todo-app/task/task-done/","title":"todo task complete command","text":"<p>As described in the original blog post (Step 6) we need to add complete command to mark the task as done by the given ID.</p> <p>First, we need to update the Todoer controller:</p> _todos/todo.py<pre><code>...\nclass Todoer:\n...\ndef set_done(self, todo_id: int) -&gt; CurrentTodo:\n\"\"\"Set a to-do as done.\"\"\"\nread = self._db_handler.read_todos()\nif read.error:\nreturn CurrentTodo({}, read.error)\ntry:\ntodo = read.todo_list[self.project_name][todo_id - 1]\nexcept IndexError:\nreturn CurrentTodo({}, ID_ERROR)\ntodo[0] = \"Done\"\nwrite = self._db_handler.write_todos(read.todo_list)\nreturn CurrentTodo(write.todo_list, write.error)\n...\n</code></pre> <p>The next thing is to create the <code>complete.py</code> file in the <code>task</code> package:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 complete.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 delete.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 list.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n3 directories, 12 files\n</code></pre> <p>Let's write our complete function:</p> task/complete.py<pre><code>from _todos import todo\ndef complete(project_name: str, task_id: int) -&gt; None:\n\"\"\"\n    Set to done given task. Mark as complete.\n    Args:\n        project_name (str): the project name\n        task_id (str): the task id to be removed\n    Return: None\n    \"\"\"\ntodo_ = todo.get_todoer(project_name)\ntodo_.set_done(task_id)\nprint(\"Success\")\n</code></pre> <p>That's it, again no need for registering your command to CLI: it is already considered as CLI command.</p> <p>Currently, we have 4 task commands:</p> <pre><code>$ /todo task -h\nusage: todo task [-h] {add,complete,delete,list} ...\npositional arguments:\n  {add,complete,delete,list}\n    add                 Add task to the project\n    complete            Set to done given task. Mark as complete.\n    delete              Delete given task from the project\n    list                Show all tasks in the given project\noptional arguments:\n  -h, --help            show this help message and exit\n</code></pre> <p>Run the command:</p> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 X morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n</code></pre> <pre><code>$ ./todo task complete daily 1\nSuccess\n</code></pre> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 &gt; morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n</code></pre> <p>As you have already noticed, the status has been changed from \"X\" to \"&gt;\" marking it as a Done.</p> <p>In raw <code>daily.json</code> file it is updated as well:</p> <p><code>{\"daily\": [[\"Done\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"]]}</code></p>"},{"location":"todo-app/task/task-list/","title":"todo task list command","text":"<p>It should be easier to get back registered tasks back using CLI, rather than looking at <code>.json</code> files. So we are going to add simple command to list available tasks in the given project. We have changed the implementation described here: Implement the list Command </p> <p>Create <code>list.py</code> file:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 task\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 add.py\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 list.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n3 directories, 10 files\n</code></pre> <p>Implementation:</p> list.py<pre><code>import os\nfrom _todos import todo\ndef list(project_name: str) -&gt; None:\n\"\"\"\n    Show all tasks in the given project\n    Args:\n        project_name (str): the project name\n    Return: None\n    \"\"\"\ntodo_ = todo.get_todoer(project_name)\ntodo_list = todo_.get_todo_list()\n_format_output(todo_list)\ndef _format_output(stdout: list[list[str, any]]) -&gt; None:\nheaders = (\"ID. \", \"Is Done \", \"| Description\")\nprint(\"\".join(headers))\nfor id_, t in enumerate(stdout, 1):\nstatus = \"X\" if t[0] == 'Todo' else \"&gt;\"\nprint(id_, status, t[1])\n</code></pre> <p>Now, we need to add the <code>get_todo_list()</code> method to the Todoer class:</p> _todos/todo.py<pre><code>...\nclass Todoer:\n...\ndef get_todo_list(self) -&gt; list[list[str, Any]]:\n\"\"\"Return the current to-do list.\"\"\"\nread = self._db_handler.read_todos()\nreturn read.todo_list[self.project_name]\n...\n</code></pre> <p>Getting help and running the command:</p> <pre><code>$ ./todo task list -h\nusage: todo task list [-h] project_name\npositional arguments:\n  project_name  the project name\noptional arguments:\n  -h, --help    show this help message and exit\n</code></pre> <p>If you have noticed, the <code>_format_output()</code> function was not considered as a command - as it is a \"non-public\" function based on Python convention.</p> <p>Let's run the actual command:</p> <pre><code>$ ./todo task list daily\nID. Is Done | Description\n1 X morning walk\n2 X night walk\n3 X gym\n4 X eat vegetables\n5 X eat fruits\n</code></pre> <p>How about adding separate versions to our commands? It is possible to have different commands from various resources, and they can have different versioning. It is easy to implement it with DynaCLI, just add <code>__version__</code> to the <code>list.py</code> file:</p> list.py<pre><code>import os\nfrom _todos import todo\n__version__ = \"1.1\"\n</code></pre> <p>Checking versions:</p> <pre><code>$ ./todo --version\ntodo - v1.0\n</code></pre> <pre><code>$ ./todo task list --version\ntodo task list - v1.1\n</code></pre> <p>So your main CLI and your commands can have different versions.</p> <p>The next is to add a command for deleting the task.</p>"},{"location":"todo-app/task/todo-app-database-handler/","title":"Setup the database operations","text":"<p>Here we grab Step 2 and Step 4 from the original article and mostly ignored other code portions.</p> <p>As we have several helper codes we can store them in the <code>_todos</code> package:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u2514\u2500\u2500 __init__.py\n2 directories, 6 files\n</code></pre> <p>Let's add some preliminary constants:</p> __init__.py<pre><code>(\nSUCCESS,\nDIR_ERROR,\nFILE_ERROR,\nDB_READ_ERROR,\nDB_WRITE_ERROR,\nJSON_ERROR,\nID_ERROR,\n) = range(7)\nERRORS = {\nDIR_ERROR: \"config directory error\",\nFILE_ERROR: \"config file error\",\nDB_READ_ERROR: \"database read error\",\nDB_WRITE_ERROR: \"database write error\",\nID_ERROR: \"to-do id error\",\n}\n</code></pre> <p>As you may notice we have removed redundant app name and version information from the <code>__init__.py</code> which was described in Step 2.</p> <p>Let's add our database handler class:</p> database.py<pre><code>import json\nfrom typing import NamedTuple, Any\nfrom . import JSON_ERROR, SUCCESS, DB_READ_ERROR, DB_WRITE_ERROR\nclass DBResponse(NamedTuple):\ntodo_list: dict[str, list[list[str, Any]]]\nerror: int\nclass DatabaseHandler:\ndef __init__(self, db_path: str) -&gt; None:\nself._db_path = db_path\ndef read_todos(self) -&gt; DBResponse:\ntry:\nwith open(self._db_path, \"r\") as db:\ntry:\nreturn DBResponse(json.loads(db.readline()), SUCCESS)\nexcept json.JSONDecodeError:  # Catch wrong JSON format\nreturn DBResponse({}, JSON_ERROR)\nexcept OSError:  # Catch file IO problems\nreturn DBResponse({}, DB_READ_ERROR)\ndef write_todos(self, todo_list: dict[str, list[list[str, Any]]]) -&gt; DBResponse:\ntry:\nwith open(self._db_path, \"w\") as db:\njson.dump(todo_list, db)\nreturn DBResponse(todo_list, SUCCESS)\nexcept OSError:  # Catch file IO problems\nreturn DBResponse(todo_list, DB_WRITE_ERROR)\n</code></pre> <p>Again, we have slightly changed the code but most of it is from Step 4.</p> <p>We added an extra package to our CLI path, it should be broken right now? Of course not.</p> <p>In pure Python convention, the names which are started with <code>_</code>(underscore) are considered \"non-public\". DynaCLI follows this convention, and we just ignore \"non-public\" packages - they are not considered as part of CLI.</p> <p>The next is to add a Controller class for our TODOs.</p>"},{"location":"todo-app/task/todo-controller-class/","title":"Setup todo controller class","text":"<p>This section is primarily adopted from Step 4 and Step 5</p> <p>Again we have omitted redundant parts and kept only needed code portions.</p> <p>Let's create the <code>todo.py</code> file in our <code>_todos</code> package:</p> <pre><code>$ tree\n.\n\u2514\u2500\u2500 TODO\n    \u251c\u2500\u2500 init.py\n    \u251c\u2500\u2500 remove.py\n    \u251c\u2500\u2500 rename.py\n    \u251c\u2500\u2500 todo\n    \u2514\u2500\u2500 _todos\n        \u251c\u2500\u2500 database.py\n        \u251c\u2500\u2500 __init__.py\n        \u2514\u2500\u2500 todo.py\n2 directories, 7 files\n</code></pre> <p>And add our controller class:</p> todo.py<pre><code>import os\nfrom .database import DatabaseHandler\nfrom typing import NamedTuple, Any\nfrom . import DB_READ_ERROR, ID_ERROR\nDIR = os.path.dirname(__file__)\nclass CurrentTodo(NamedTuple):\ntodo: dict[str, list[list[str, Any]]]\nerror: int\nclass Todoer:\ndef __init__(self, project_name: str) -&gt; None:\nself.project_name = project_name\nself._db_handler = DatabaseHandler(DIR + f\"/../{project_name}.json\")\ndef get_todoer(project_name: str) -&gt; Todoer:\nreturn Todoer(project_name)\n</code></pre> <p>We have added the <code>get_todoer</code> function to get back the Todoer object - it will be used in the actual CLI commands.</p> <p>The next is to implement the task-adding CLI command.</p>"}]}